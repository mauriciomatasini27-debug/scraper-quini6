# Scraper Quini 6 - AÃ±o 2025

Script en TypeScript para extraer todos los resultados histÃ³ricos del Quini 6 correspondientes al aÃ±o 2025 desde https://www.quini-6.com.ar/.

## ğŸš€ CaracterÃ­sticas

- âœ… ExtracciÃ³n completa de todos los sorteos del aÃ±o 2025
- âœ… Tipado estricto en TypeScript
- âœ… ValidaciÃ³n automÃ¡tica de integridad de datos
- âœ… Sistema de reintentos para manejo de errores
- âœ… ExtracciÃ³n de todas las modalidades:
  - Tradicional Primer Sorteo
  - Tradicional la Segunda
  - Revancha
  - El Quini que Siempre Sale
  - Pozo Extra
- âœ… Guardado en formato JSON estructurado

## ğŸ“‹ Requisitos

- Node.js 18 o superior
- npm o yarn

## ğŸ”§ InstalaciÃ³n

1. Instalar dependencias:
```bash
npm install
```

2. Instalar los navegadores de Playwright:
```bash
npx playwright install chromium
```

## ğŸ¯ Uso

### Ejecutar el scraper manualmente:

```bash
npm run scrape
```

O en modo desarrollo (con ts-node):

```bash
npm run dev
```

### Scraping por aÃ±o especÃ­fico:

```bash
npm run scrape:2024    # Extraer aÃ±o 2024
npm run scrape:2025    # Extraer aÃ±o 2025
npm run scrape:2020-2023  # Extraer aÃ±os 2020-2023
```

### ğŸ¤– Ejecutar el Scheduler AutomÃ¡tico:

#### OpciÃ³n 1: GitHub Actions (Recomendado) â­

El workflow de GitHub Actions ejecuta el scraping automÃ¡ticamente los **miÃ©rcoles y domingos a las 21:30 ARG**:

1. Configura los secretos en GitHub (ver [GITHUB_ACTIONS_SETUP.md](./GITHUB_ACTIONS_SETUP.md))
2. El workflow se ejecutarÃ¡ automÃ¡ticamente segÃºn el cron configurado
3. Los resultados se guardan como artifacts y en Supabase (opcional)

**Ventajas**:
- âœ… Gratuito para repositorios pÃºblicos
- âœ… No requiere servidor propio
- âœ… Completamente automatizado en la nube
- âœ… Historial completo de ejecuciones

#### OpciÃ³n 2: Scheduler Local

Ejecuta el scraping localmente los **miÃ©rcoles y domingos a las 20:00**:

```bash
npm run scheduler
```

Ver [SCHEDULER.md](./SCHEDULER.md) para mÃ¡s informaciÃ³n sobre cÃ³mo configurar el scheduler como servicio local.

### Compilar TypeScript:

```bash
npm run build
```

### Ejecutar la versiÃ³n compilada:

```bash
npm start
```

## ğŸ“ Estructura del Proyecto

```
scraperquini6/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts          # Punto de entrada principal
â”‚   â”œâ”€â”€ scraper.ts        # LÃ³gica de scraping con Playwright
â”‚   â”œâ”€â”€ validator.ts      # ValidaciÃ³n de datos extraÃ­dos
â”‚   â””â”€â”€ types.ts          # Definiciones de tipos TypeScript
â”œâ”€â”€ data/                 # Directorio de salida (se crea automÃ¡ticamente)
â”‚   â””â”€â”€ quini_2025_completo.json
â”œâ”€â”€ dist/                 # CÃ³digo compilado (se crea automÃ¡ticamente)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## ğŸ“Š Formato de Salida

Los resultados se guardan en `data/quini_2025_completo.json` con la siguiente estructura:

```json
{
  "aÃ±o": 2025,
  "totalSorteos": 165,
  "sorteos": [
    {
      "numeroSorteo": 3333,
      "fecha": "24/12/2025",
      "fechaISO": "2025-12-24",
      "tradicional": {
        "nombre": "Tradicional Primer Sorteo",
        "numeros": {
          "numero1": "08",
          "numero2": "10",
          "numero3": "25",
          "numero4": "33",
          "numero5": "35",
          "numero6": "42"
        }
      },
      "segunda": { ... },
      "revancha": { ... },
      "siempreSale": { ... },
      "pozoExtra": {
        "ganadores": 194,
        "premio": "670.103,09"
      },
      "url": "https://www.quini-6.com.ar/2025/12/resultados-del-24122025_24.html",
      "extraidoEn": "2025-12-25T10:30:00.000Z"
    }
  ],
  "sorteosPendientes": [],
  "errores": [],
  "fechaInicio": "2025-01-01",
  "fechaFin": "2025-12-24",
  "metadata": {
    "version": "1.0.0",
    "fechaExtraccion": "2025-12-25T10:30:00.000Z"
  }
}
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno (Opcional)

Crea un archivo `.env` en la raÃ­z del proyecto si deseas usar Crawlbase o Supabase:

```env
CRAWLBASE_JS_TOKEN=tu_token_aqui
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=tu_service_role_key
```

### ConfiguraciÃ³n de GitHub Actions

Para automatizaciÃ³n completa en la nube, configura GitHub Actions:

1. Ve a **Settings â†’ Secrets and variables â†’ Actions**
2. Agrega los secretos: `CRAWLBASE_JS_TOKEN`, `SUPABASE_URL`, `SUPABASE_KEY`
3. El workflow se ejecutarÃ¡ automÃ¡ticamente segÃºn el cron

Ver [GITHUB_ACTIONS_SETUP.md](./GITHUB_ACTIONS_SETUP.md) para instrucciones detalladas.

### ConfiguraciÃ³n de Supabase (Opcional)

Si quieres almacenar los datos en Supabase, sigue la guÃ­a en [SUPABASE_SETUP.md](./SUPABASE_SETUP.md) para configurar la base de datos.

### ConfiguraciÃ³n del Scraper

El scraper incluye las siguientes configuraciones por defecto:

- **AÃ±o objetivo**: 2025 (configurable en `scraper.ts`)
- **MÃ¡ximo de reintentos**: 3
- **Delay entre requests**: 2 segundos
- **Timeout de pÃ¡gina**: 30 segundos

Puedes modificar estos valores en `src/scraper.ts`:

```typescript
private aÃ±o = 2025;
private maxReintentos = 3;
private delayEntreRequests = 2000;
```

## ğŸ” ValidaciÃ³n

El scraper incluye un sistema de validaciÃ³n que verifica:

- âœ… Que no falten sorteos en el rango
- âœ… Que cada sorteo tenga todos los datos requeridos
- âœ… Que las fechas estÃ©n en orden cronolÃ³gico
- âœ… Que los nÃºmeros estÃ©n en el rango vÃ¡lido (00-45)
- âœ… Que el formato de los datos sea correcto

## âš ï¸ Manejo de Errores

- Si una pÃ¡gina no carga, el scraper intentarÃ¡ hasta 3 veces antes de marcarla como pendiente
- Los sorteos que no se puedan extraer se registrarÃ¡n en `sorteosPendientes`
- Todos los errores se registrarÃ¡n en el array `errores` del JSON de salida

## ğŸ›¡ï¸ Consideraciones

- El scraper respeta los tiempos de espera entre requests para no sobrecargar el servidor
- Usa un User-Agent estÃ¡ndar para evitar bloqueos
- Si detectas problemas de captcha o bloqueos, puedes usar el token de Crawlbase (ver cÃ³digo)

## ğŸ“ Notas

- El proceso puede tardar varios minutos dependiendo de la cantidad de sorteos
- Se recomienda ejecutar en un entorno estable con buena conexiÃ³n a internet
- Los datos se guardan automÃ¡ticamente al finalizar el proceso

## ğŸ› SoluciÃ³n de Problemas

### Error: "PÃ¡gina no inicializada"
- AsegÃºrate de que Playwright estÃ© instalado correctamente
- Ejecuta `npx playwright install chromium`

### Error: "No se encontraron enlaces de sorteos"
- Verifica tu conexiÃ³n a internet
- El sitio puede estar temporalmente no disponible

### Sorteos faltantes
- Revisa el array `sorteosPendientes` en el JSON de salida
- Puedes ejecutar el scraper nuevamente para intentar obtenerlos

## ğŸ“„ Licencia

MIT

