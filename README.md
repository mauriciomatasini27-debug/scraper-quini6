# üé∞ Scraper Automatizado Quini 6

Sistema completo de web scraping automatizado para extraer, validar y almacenar resultados hist√≥ricos del Quini 6 desde 2020 hasta la fecha actual. Incluye automatizaci√≥n mediante GitHub Actions, integraci√≥n con Supabase, y scraping incremental para actualizaciones eficientes.

[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue)](https://www.typescriptlang.org/)
[![Playwright](https://img.shields.io/badge/Playwright-1.40-green)](https://playwright.dev/)
[![Node.js](https://img.shields.io/badge/Node.js-20+-brightgreen)](https://nodejs.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

---

## üìã Tabla de Contenidos

- [Caracter√≠sticas Principales](#-caracter√≠sticas-principales)
- [Tecnolog√≠as Utilizadas](#-tecnolog√≠as-utilizadas)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Arquitectura del Proyecto](#-arquitectura-del-proyecto)
- [Configuraci√≥n](#-configuraci√≥n)
- [Automatizaci√≥n](#-automatizaci√≥n)
- [Base de Datos](#-base-de-datos)
- [Estructura de Datos](#-estructura-de-datos)
- [Validaci√≥n](#-validaci√≥n)
- [Documentaci√≥n Adicional](#-documentaci√≥n-adicional)
- [Soluci√≥n de Problemas](#-soluci√≥n-de-problemas)
- [Contribuci√≥n](#-contribuci√≥n)
- [Licencia](#-licencia)

---

## üöÄ Caracter√≠sticas Principales

### ‚ú® Funcionalidades Core

- ‚úÖ **Extracci√≥n Completa**: Scraping de todos los sorteos hist√≥ricos (2020-2025)
- ‚úÖ **Tipado Estricto**: TypeScript con interfaces y tipos definidos
- ‚úÖ **Validaci√≥n Autom√°tica**: Sistema exhaustivo de validaci√≥n de integridad de datos
- ‚úÖ **Manejo Robusto de Errores**: Sistema de reintentos (hasta 3 intentos por sorteo)
- ‚úÖ **Scraping Incremental**: Solo extrae sorteos nuevos, optimizando tiempo y recursos
- ‚úÖ **M√∫ltiples Modalidades**: Extrae datos de 5 modalidades por sorteo:
  - Tradicional Primer Sorteo
  - Tradicional la Segunda
  - Revancha
  - El Quini que Siempre Sale
  - Pozo Extra (cuando aplica)

### ü§ñ Automatizaci√≥n

- ‚úÖ **GitHub Actions**: Workflow automatizado que se ejecuta mi√©rcoles y domingos
- ‚úÖ **Cron Jobs Locales**: Scheduler con node-cron para ejecuci√≥n local
- ‚úÖ **Scraping Incremental**: Compara con datos existentes y solo extrae lo nuevo
- ‚úÖ **Persistencia de Artifacts**: Descarga autom√°tica de datos previos en GitHub Actions

### üíæ Integraci√≥n con Base de Datos

- ‚úÖ **Supabase Integration**: Guardado autom√°tico en Supabase (PostgreSQL)
- ‚úÖ **Importaci√≥n Masiva**: Scripts para importar datos hist√≥ricos (2020-2025)
- ‚úÖ **Operaciones Batch**: Upsert masivo optimizado para miles de registros
- ‚úÖ **Doble M√©todo**: Soporte para REST API y conexi√≥n directa PostgreSQL

### üîç Validaci√≥n y Calidad

- ‚úÖ **Verificaci√≥n de Integridad**: Detecta sorteos faltantes en rangos
- ‚úÖ **Validaci√≥n de Formato**: Verifica que los n√∫meros est√©n en rango v√°lido (00-45)
- ‚úÖ **Orden Cronol√≥gico**: Valida que las fechas est√©n en orden correcto
- ‚úÖ **Datos Completos**: Verifica que cada sorteo tenga todos los campos requeridos

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Lenguajes y Runtime
- **TypeScript 5.3**: Lenguaje principal con tipado est√°tico estricto
- **Node.js 20+**: Runtime de ejecuci√≥n
- **CommonJS**: Sistema de m√≥dulos

### Librer√≠as Principales
- **Playwright 1.40**: Automatizaci√≥n de navegador headless para web scraping
- **@supabase/supabase-js 2.89**: Cliente oficial de Supabase para integraci√≥n REST API
- **pg 8.16**: Cliente PostgreSQL nativo para conexi√≥n directa
- **node-cron 3.0**: Programaci√≥n de tareas automatizadas
- **dotenv**: Gesti√≥n de variables de entorno

### Herramientas de Desarrollo
- **ts-node**: Ejecuci√≥n directa de TypeScript sin compilaci√≥n previa
- **TypeScript Compiler**: Compilaci√≥n y validaci√≥n de tipos
- **Git**: Control de versiones
- **npm**: Gesti√≥n de dependencias

### Plataformas y Servicios
- **GitHub Actions**: CI/CD y automatizaci√≥n en la nube
- **Supabase**: Base de datos PostgreSQL como servicio
- **PostgreSQL**: Base de datos relacional
- **Crawlbase** (opcional): Servicio anti-CAPTCHA para casos especiales

---

## üì¶ Instalaci√≥n

### Prerrequisitos

- Node.js 18 o superior
- npm o yarn
- Git (para clonar el repositorio)

### Pasos de Instalaci√≥n

1. **Clonar el repositorio**:
```bash
git clone https://github.com/tu-usuario/scraper-quini6.git
cd scraper-quini6
```

2. **Instalar dependencias**:
```bash
npm install
```

3. **Instalar Playwright y navegadores**:
```bash
npx playwright install chromium
```

4. **Configurar variables de entorno** (opcional):
```bash
cp env.example.txt .env
# Editar .env con tus credenciales
```

---

## üéØ Uso

### Scraping Manual

#### Extraer un a√±o espec√≠fico:
```bash
# A√±o 2025 (por defecto)
npm run scrape:2025

# A√±o 2024
npm run scrape:2024

# A√±os 2020-2023
npm run scrape:2020-2023
```

#### Modo desarrollo (sin compilar):
```bash
npm run dev
```

#### Compilar y ejecutar:
```bash
npm run build
npm start
```

### Scraping Incremental

Para extraer solo los sorteos nuevos (√∫til para actualizaciones):

```bash
# Compilar primero
npm run build

# Ejecutar modo incremental
node dist/index-incremental.js [a√±o]
```

### Importar Datos Hist√≥ricos a Supabase

#### Opci√≥n 1: Usando REST API (Recomendado)
```bash
npm run import:history
```

#### Opci√≥n 2: Usando conexi√≥n directa PostgreSQL
```bash
npm run import:history:pg
```

### Scheduler Local

Para ejecutar el scraper autom√°ticamente los mi√©rcoles y domingos:

```bash
npm run scheduler
```

Ver [SCHEDULER.md](./SCHEDULER.md) para m√°s detalles sobre configuraci√≥n como servicio.

---

## üèóÔ∏è Arquitectura del Proyecto

### Estructura de Directorios

```
scraperquini6/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ scraper_cron.yml      # Workflow de GitHub Actions
‚îú‚îÄ‚îÄ data/                          # Datos extra√≠dos (JSON) - NO se sube a Git
‚îÇ   ‚îú‚îÄ‚îÄ quini_2020_completo.json
‚îÇ   ‚îú‚îÄ‚îÄ quini_2021_completo.json
‚îÇ   ‚îú‚îÄ‚îÄ quini_2022_completo.json
‚îÇ   ‚îú‚îÄ‚îÄ quini_2023_completo.json
‚îÇ   ‚îú‚îÄ‚îÄ quini_2024_completo.json
‚îÇ   ‚îî‚îÄ‚îÄ quini_2025_completo.json
‚îú‚îÄ‚îÄ dist/                          # C√≥digo compilado (generado) - NO se sube a Git
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ scraper.ts                 # Clase principal de scraping
‚îÇ   ‚îú‚îÄ‚îÄ validator.ts               # Validaci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ types.ts                   # Definiciones TypeScript
‚îÇ   ‚îú‚îÄ‚îÄ supabase-client.ts         # Cliente Supabase
‚îÇ   ‚îú‚îÄ‚îÄ index.ts                   # Entry point principal
‚îÇ   ‚îú‚îÄ‚îÄ index-2024.ts              # Script espec√≠fico para 2024
‚îÇ   ‚îú‚îÄ‚îÄ index-incremental.ts       # Scraping incremental
‚îÇ   ‚îú‚îÄ‚îÄ index-multi-year.ts        # Scraping m√∫ltiples a√±os
‚îÇ   ‚îú‚îÄ‚îÄ index-scheduler.ts          # Scheduler local
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ importHistory.ts       # Importaci√≥n masiva (REST API)
‚îÇ       ‚îú‚îÄ‚îÄ importHistoryPg.ts     # Importaci√≥n masiva (PostgreSQL)
‚îÇ       ‚îî‚îÄ‚îÄ README.md               # Documentaci√≥n de scripts
‚îú‚îÄ‚îÄ .env                            # Variables de entorno (NO se sube a Git)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ README.md                       # Este archivo
‚îî‚îÄ‚îÄ [Documentaci√≥n adicional]      # Varios archivos .md de gu√≠as
```

### Componentes Principales

#### 1. `Quini6Scraper` (`src/scraper.ts`)
Clase principal que maneja todo el proceso de scraping:
- Inicializaci√≥n del navegador Playwright
- Navegaci√≥n y extracci√≥n de enlaces de sorteos
- Extracci√≥n de datos de cada sorteo
- Manejo de errores y reintentos
- Guardado de resultados en JSON

#### 2. `ValidadorSorteos` (`src/validator.ts`)
Sistema de validaci√≥n exhaustiva:
- Verificaci√≥n de sorteos faltantes
- Validaci√≥n de formato de n√∫meros
- Verificaci√≥n de orden cronol√≥gico
- Detecci√≥n de datos incompletos

#### 3. `supabase-client.ts`
Integraci√≥n con Supabase:
- Configuraci√≥n desde variables de entorno
- Mapeo de datos a formato de base de datos
- Operaciones batch (upsert masivo)
- Manejo de errores de conexi√≥n

#### 4. Scripts de Importaci√≥n
- `importHistory.ts`: Usa REST API de Supabase
- `importHistoryPg.ts`: Usa conexi√≥n directa PostgreSQL

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno

Crea un archivo `.env` en la ra√≠z del proyecto:

```env
# Crawlbase (opcional - para casos de CAPTCHA)
CRAWLBASE_JS_TOKEN=tu_token_crawlbase

# Supabase (opcional - para guardar en base de datos)
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=tu_service_role_key

# PostgreSQL Direct (opcional - alternativa a REST API)
DATABASE_URL=postgresql://user:password@host:port/database
```

**Nota**: Usa la **Service Role Key** de Supabase, no la anon key, para tener permisos completos.

Ver [CONFIGURAR_ENV.md](./CONFIGURAR_ENV.md) para m√°s detalles.

### Configuraci√≥n del Scraper

Puedes modificar estos valores en `src/scraper.ts`:

```typescript
private maxReintentos = 3;              // Reintentos por sorteo fallido
private delayEntreRequests = 2000;      // Delay entre requests (ms)
private navigationTimeout = 60000;      // Timeout de navegaci√≥n (ms)
```

### Configuraci√≥n de GitHub Actions

1. Ve a **Settings ‚Üí Secrets and variables ‚Üí Actions** en tu repositorio
2. Agrega los siguientes secretos:
   - `CRAWLBASE_JS_TOKEN` (opcional)
   - `SUPABASE_URL`
   - `SUPABASE_KEY`

Ver [GITHUB_ACTIONS_SETUP.md](./GITHUB_ACTIONS_SETUP.md) para instrucciones detalladas.

### Configuraci√≥n de Supabase

1. Crea un proyecto en [Supabase](https://supabase.com)
2. Ejecuta el SQL en `create_table_resultados_quini.sql` para crear la tabla
3. Obt√©n tu URL y Service Role Key desde Settings ‚Üí API

Ver [SUPABASE_SETUP.md](./SUPABASE_SETUP.md) y [CREAR_TABLA_SUPABASE.md](./CREAR_TABLA_SUPABASE.md) para m√°s detalles.

---

## ü§ñ Automatizaci√≥n

### GitHub Actions (Recomendado)

El workflow se ejecuta autom√°ticamente:
- **Mi√©rcoles a las 21:00 ARG** (despu√©s del sorteo de las 19:30)
- **Domingo a las 21:00 ARG** (despu√©s del sorteo de las 19:30)

**Caracter√≠sticas**:
- ‚úÖ Descarga autom√°tica de artifacts previos
- ‚úÖ Scraping incremental (solo sorteos nuevos)
- ‚úÖ Guardado en Supabase (si est√° configurado)
- ‚úÖ Upload de artifacts para pr√≥xima ejecuci√≥n
- ‚úÖ Ejecuci√≥n manual disponible desde GitHub Actions UI

**Ver ejecuciones**: Ve a la pesta√±a "Actions" en tu repositorio de GitHub.

Ver [EJECUTAR_WORKFLOW.md](./EJECUTAR_WORKFLOW.md) para ejecutar manualmente.

### Scheduler Local

Para ejecutar localmente con node-cron:

```bash
npm run scheduler
```

El scheduler ejecutar√° el scraping los mi√©rcoles y domingos a las 20:00 (hora local).

**Ver**: [SCHEDULER.md](./SCHEDULER.md) para configuraci√≥n como servicio de Windows/Linux.

---

## üíæ Base de Datos

### Esquema de Tabla

La tabla `resultados_quini` tiene la siguiente estructura:

```sql
CREATE TABLE resultados_quini (
  id BIGSERIAL PRIMARY KEY,
  sorteo_numero INTEGER UNIQUE NOT NULL,
  fecha DATE NOT NULL,
  fecha_texto VARCHAR(20),
  a√±o INTEGER NOT NULL,
  tradicional INTEGER[] NOT NULL,
  la_segunda INTEGER[] NOT NULL,
  revancha INTEGER[] NOT NULL,
  siempre_sale INTEGER[] NOT NULL,
  pozo_extra JSONB,
  url TEXT,
  extraido_en TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

Ver `create_table_resultados_quini.sql` para el script completo.

### Importaci√≥n de Datos

#### Importar todos los datos hist√≥ricos (2020-2025):

```bash
# Opci√≥n 1: REST API (m√°s simple)
npm run import:history

# Opci√≥n 2: PostgreSQL directo (m√°s r√°pido para grandes vol√∫menes)
npm run import:history:pg
```

**Nota**: Los scripts detectan y eliminan duplicados autom√°ticamente antes de insertar.

Ver [src/scripts/README.md](./src/scripts/README.md) para m√°s detalles.

---

## üìä Estructura de Datos

### Formato JSON de Salida

Los resultados se guardan en `data/quini_[a√±o]_completo.json`:

```json
{
  "a√±o": 2025,
  "totalSorteos": 165,
  "sorteos": [
    {
      "numeroSorteo": 3333,
      "fecha": "24/12/2025",
      "fechaISO": "2025-12-24",
      "tradicional": {
        "nombre": "Tradicional Primer Sorteo",
        "numeros": {
          "numero1": "08",
          "numero2": "10",
          "numero3": "25",
          "numero4": "33",
          "numero5": "35",
          "numero6": "42"
        }
      },
      "segunda": { /* ... */ },
      "revancha": { /* ... */ },
      "siempreSale": { /* ... */ },
      "pozoExtra": {
        "ganadores": 194,
        "premio": "670.103,09"
      },
      "url": "https://www.quini-6.com.ar/2025/12/resultados-del-24122025_24.html",
      "extraidoEn": "2025-12-25T10:30:00.000Z"
    }
  ],
  "sorteosPendientes": [],
  "errores": [],
  "fechaInicio": "2025-01-01",
  "fechaFin": "2025-12-24",
  "metadata": {
    "version": "1.0.0",
    "fechaExtraccion": "2025-12-25T10:30:00.000Z"
  }
}
```

### Mapeo a Base de Datos

Los n√∫meros se transforman de objetos a arrays:
- `tradicional.numeros` ‚Üí `tradicional INTEGER[]`
- `segunda.numeros` ‚Üí `la_segunda INTEGER[]`
- `revancha.numeros` ‚Üí `revancha INTEGER[]`
- `siempreSale.numeros` ‚Üí `siempre_sale INTEGER[]`

---

## üîç Validaci√≥n

El sistema de validaci√≥n verifica:

1. **Integridad de Rangos**: Detecta sorteos faltantes entre el primero y √∫ltimo sorteo del a√±o
2. **Formato de N√∫meros**: Verifica que todos los n√∫meros est√©n en rango v√°lido (00-45)
3. **Orden Cronol√≥gico**: Valida que las fechas est√©n en orden ascendente
4. **Datos Completos**: Verifica que cada sorteo tenga todas las modalidades requeridas
5. **Formato de Fechas**: Valida formato ISO y formato legible

**Ejemplo de salida de validaci√≥n**:
```
üîç Validando sorteos del #3000 al #3333...
‚úÖ Validaci√≥n completada:
   - Total sorteos: 165
   - Sorteos faltantes: 0
   - Advertencias: 0
```

---

## üìö Documentaci√≥n Adicional

El proyecto incluye documentaci√≥n detallada en varios archivos:

- **[GITHUB_ACTIONS_SETUP.md](./GITHUB_ACTIONS_SETUP.md)**: Configuraci√≥n de GitHub Actions
- **[SUPABASE_SETUP.md](./SUPABASE_SETUP.md)**: Configuraci√≥n de Supabase
- **[CREAR_TABLA_SUPABASE.md](./CREAR_TABLA_SUPABASE.md)**: Gu√≠a paso a paso para crear la tabla
- **[SCHEDULER.md](./SCHEDULER.md)**: Configuraci√≥n del scheduler local
- **[CONFIGURAR_ENV.md](./CONFIGURAR_ENV.md)**: Configuraci√≥n de variables de entorno
- **[ACTUALIZAR_ENV.md](./ACTUALIZAR_ENV.md)**: Actualizar variables de entorno para PostgreSQL
- **[src/scripts/README.md](./src/scripts/README.md)**: Documentaci√≥n de scripts de importaci√≥n
- **[EJECUTAR_WORKFLOW.md](./EJECUTAR_WORKFLOW.md)**: C√≥mo ejecutar workflows manualmente
- **[GIT_SETUP.md](./GIT_SETUP.md)**: Configuraci√≥n de Git
- **[CONFIGURAR_GITHUB.md](./CONFIGURAR_GITHUB.md)**: Configurar repositorio remoto
- **[VERIFICAR_REPOSITORIO.md](./VERIFICAR_REPOSITORIO.md)**: Verificar informaci√≥n del repositorio

---

## üêõ Soluci√≥n de Problemas

### Error: "P√°gina no inicializada"
**Soluci√≥n**: Aseg√∫rate de que Playwright est√© instalado:
```bash
npx playwright install chromium
```

### Error: "No se encontraron enlaces de sorteos"
**Causas posibles**:
- Problemas de conexi√≥n a internet
- El sitio est√° temporalmente no disponible
- Cambios en la estructura HTML del sitio

**Soluci√≥n**: Verifica tu conexi√≥n y ejecuta nuevamente. Si persiste, revisa los selectores en `scraper.ts`.

### Sorteos Faltantes
**Causa**: Algunos sorteos pueden fallar en la extracci√≥n inicial.

**Soluci√≥n**: 
1. Revisa el array `sorteosPendientes` en el JSON de salida
2. Ejecuta el scraper nuevamente (solo procesar√° los faltantes si usas modo incremental)

### Error de Supabase: "ON CONFLICT DO UPDATE command cannot affect row a second time"
**Causa**: Duplicados dentro del mismo batch.

**Soluci√≥n**: Los scripts de importaci√≥n ya manejan esto autom√°ticamente eliminando duplicados antes de insertar.

### Timeout en GitHub Actions
**Soluci√≥n**: Aumenta el timeout en el workflow o divide la ejecuci√≥n en batches m√°s peque√±os.

---

## üìà Mejoras Futuras

- [ ] Soporte para otros juegos de loter√≠a
- [ ] Dashboard web para visualizar datos
- [ ] API REST para consultar datos
- [ ] An√°lisis estad√≠stico de n√∫meros
- [ ] Notificaciones cuando hay sorteos nuevos
- [ ] Exportaci√≥n a otros formatos (CSV, Excel)

---

## ü§ù Contribuci√≥n

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo [LICENSE](./LICENSE) para m√°s detalles.

---

## üë§ Autor

Desarrollado con ‚ù§Ô∏è para extracci√≥n automatizada de datos p√∫blicos.

---

## üôè Agradecimientos

- [Playwright](https://playwright.dev/) por la excelente herramienta de automatizaci√≥n
- [Supabase](https://supabase.com/) por el servicio de base de datos
- [GitHub Actions](https://github.com/features/actions) por la plataforma de CI/CD

---

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub!**
